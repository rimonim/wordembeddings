% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fcm_operations.R
\name{fcm_pmi}
\alias{fcm_pmi}
\alias{fcm_smooth}
\alias{fcm_positive}
\alias{fcm_log}
\title{Transform a feature co-occurrence matrix}
\usage{
fcm_pmi(fcm, positive = TRUE, smoothing = 1, shift = 0, base = 2, prob = NULL)

fcm_smooth(fcm, method = "goodturing", crit = 1.96, estimate_zeros = TRUE)

fcm_positive(fcm)

fcm_log(fcm, positive = TRUE, base = 2)
}
\arguments{
\item{fcm}{a \link[quanteda:fcm]{Quanteda fcm} or similar 2D matrix-like or 3D array-like object}

\item{positive}{logical. If \code{TRUE}, all negative elements are replaced with zeros.}

\item{smoothing}{the smoothing parameter for estimating the context (i.e. fcm columns) distribution.}

\item{shift}{numeric. A number added to each element of the output (see details).}

\item{base}{the base with which to compute logarithms}

\item{prob}{\code{"rows"} indicates that elements are row probabilities (i.e. row sums
are assumed to be 1). \code{"cols"} indicates that elements are column probabilities
(i.e. column sums are assumed to be 1). If \code{NULL} (the default), elements are
taken as raw counts.}

\item{method}{smoothing method:
\describe{
\item{\code{goodturing}}{the "Simple Good-Turing" algorithm described by Gale &
Sampson (1995)}
\item{\code{laplace}}{Laplace (a.k.a. "add one") smoothing}
}}

\item{crit}{criterion for switching between raw and smoothed estimates when
\code{method = "goodturing"}. The default \code{1.96} corresponds to the standard
0.05 significance criterion.}

\item{estimate_zeros}{logical; if \code{TRUE}, distribute the estimated
probability of unobserved tokens among features with a count of zero in
each document when \code{method = "goodturing"}. Note that this coerces the
output to a dense matrix, so may exceed memory requirements for large FCMs.}
}
\description{
\code{fcm_pmi()} calculates the Pointwise Mutual Information between each word and
context (i.e. row and column) of the matrix. \code{fcm_log()} takes the logarithm
of each element. \code{fcm_smooth()} re-weights observed co-occurrence frequencies
to account for unobserved values.
}
\details{
If \code{fcm} is a 3D array or SparseArray, it is taken as a stack of feature
co-occurrence matrices. In other words, PMI is calculated for rows and
columns within each level of the third dimension.
When calculating PMI, context counts are raised to the power of \code{smoothing}.
Mikolov et al. (2013) found \code{smoothing = .75} to work well in the context of
the word2vec algorithm.
The shift parameter controls the prior probability of observing a true
co-occurence as opposed to a randomly sampled ("negative") one.
Thus \code{shift = -log(k, base)} is analogous to the Skip-gram algorithm with k
negative samples. \code{shift = log(sum(fcm), base)} is analogous to the GloVe
algorithm with weights fixed at log frequency.
}
\references{
Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111â€“3119.
}
